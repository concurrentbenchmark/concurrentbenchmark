\documentclass[runningheads]{llncs}
\synctex=1
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{mathpartir}
\usepackage{cite}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage[inline]{enumitem}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage[status=draft]{fixme}
\fxsetup{theme=color}
% \setlength{\textwidth}{12.4cm}
\setlength{\textheight}{19.9cm}

\input{../macros.tex}

\begin{document}

\title{The Concurrent Calculi Formalisation Benchmark}

\author{
     Marco Carbone \inst{1}\orcidID{0000-0001-9479-2632}
\and David Castro-Perez \inst{2}\orcidID{0000-0002-6939-4189}
\and Francisco Ferreira \inst{3}\orcidID{0000-0001-8494-7696}
\and Lorenzo Gheri \inst{4}\orcidID{0000-0002-3191-7722}
\and Frederik Krogsdal Jacobsen \inst{5}\orcidID{0000-0003-3651-8314}
\and Alberto Momigliano \inst{6}\orcidID{0000-0003-0942-4777}
\and Luca Padovani \inst{7}\orcidID{0000-0001-9097-1297}
\and Alceste Scalas \inst{5}\orcidID{0000-0002-1153-6164}
\and Dawit Tirore \inst{1}\orcidID{0000-0002-1997-5161}
\and Martin Vassor \inst{8}\orcidID{0000-0002-2057-0495}
\and Nobuko Yoshida \inst{8}\orcidID{0000-0002-3925-8557}
\and Daniel Zackon \inst{9}\orcidID{0009-0008-6153-2955}
}

\institute{
     IT University of Copenhagen, Copenhagen, Denmark \email{maca@itu.dk}, \email{dati@itu.dk}
\and University of Kent, Canterbury, United Kingdom \email{D.Castro-Perez@kent.ac.uk}
\and Royal Holloway, University of London, Egham, United Kingdom \email{Francisco.FerreiraRuiz@rhul.ac.uk}
\and University of Liverpool, Liverpool, United Kingdom \email{Lorenzo.Gheri@liverpool.ac.uk}
\and Technical University of Denmark, Kgs. Lyngby, Denmark \email{fkjac@dtu.dk}, \email{alcsc@dtu.dk}
\and Università degli Studi di Milano, Milan, Italy \email{momigliano@di.unimi.it}
\and Università di Camerino, Camerino, Italy \email{luca.padovani@unicam.it}
\and University of Oxford, Oxford, United Kingdom \email{martin.vassor@cs.ox.ac.uk}, \email{nobuko.yoshida@cs.ox.ac.uk}
\and McGill University, Montreal, Canada \email{daniel.zackon@mcgill.ca}
}

\authorrunning{M. Carbone et al.}

\maketitle

\begin{abstract}
  POPLMark and POPLMark Reloaded sparked a flurry of work on machine-checked proofs, and fostered the adoption of proof mechanisation in programming language research.
  Both challenges were purposely limited in scope, and their benchmark problems do not address concurrency-related issues.
  %
  We propose a new collection of benchmark problems focused on the difficulties that typically arise when mechanising formal models of concurrent and distributed programming languages, such as process calculi.
  Our benchmark problems address three key topics: linearity, scope extrusion, and coinductive reasoning.
  The goal of this new challenge is to clarify, compare, and advance the state of the art, fostering the adoption of proof mechanisation in future research on message-passing concurrency.

\keywords{Mechanisation \and Process calculi \and Benchmark \and Coinduction \and Scope extrusion \and Linearity}
\end{abstract}

% - Introduction
%   - POPLMark accelerated progress in mechanisation tools for PL
%     - POPLMark Reloaded tried to do the same for logical relations
%     - But they were deliberately limited in scope to not include process calculi
%   - We propose a new collection of benchmark problems for process calculi
%     - Why not concurrency in general? (after this point, only mention process calculi)
%     - Why is there a problem with process calculus mechanisations?
%     - Our experience says there is, and we will cite other experiences below
%   - We have noticed three key issues
%     - They are not covered by POPLMark
%     - Techniques are less settled than for binders
%     - Others also mention them as problems: cite and explain references briefly for each challenge topic
%   - Our goals are to determine the state of the art, develop best practices and tutorials, and identify improvements to proof assistant technology that would materially help the situation
\section{Introduction}
The POPLMark challenge~\cite{POPLMark} accelerated the development of proof assistants, libraries, and best practices for programming language mechanisation by establishing a common ground for systematically evaluating mechanisation techniques.
In doing so, it spearheaded a shift in the programming language research community towards publications that include mechanised proofs.
POPLMark Reloaded~\cite{POPLMarkReloaded} proposed a similar program for proofs involving logical relations.
These challenges, and therefore the developments they spurred, were deliberately limited in scope, but their authors noted the need for future benchmarks to tackle such areas as coinduction and linear environments.

In this spirit, we propose a new collection of benchmark problems specifically designed to address typical issues that arise when mechanising formal models of concurrent and distributed programming languages in general, and process calculi in particular. 
While results about such formalisms have already been mechanised (as we will discuss further below), our experience is that choosing appropriate mechanisation techniques and tools remains a significant challenge and that the trade-offs are not well understood.
This often leads researchers toward a trial-and-error approach, resulting in sub-optimal solutions, wasted mechanisation effort, and techniques and results that are hard to reuse.

Our benchmark problems (explained in detail in \cref{app:challenges}) are designed to focus on three key aspects which typically cause difficulties when mechanising concurrency theory: \emph{linearity}, \emph{scope extrusion}, and \emph{coinductive reasoning}.
The mechanisation of novel research results often requires addressing more than just one of these aspects at once; we see the combination of techniques as a next step beyond the scope of this challenge, as discussed further in \Cref{sec:going-beyond}.
Our benchmark challenges are based on process calculi, as these provide a simple but realistic exhibit of the issues typically encountered when mechanising the three key aspects.
These three aspects are certainly not the only causes of difficulties, but they are fundamental to concurrency theory, and emerge in most mechanisations, as we will see presently while discussing the issues presented by them.

\todo{These paragraphs are still quite messy and unfocused. They should focus on the motivation, i.e.\ mention what others have perceived as problems.}
\paragraph{Linearity.}
In mechanised meta-theory, addressing linearity means choosing an appropriate representation of the linear context.
The crux of the matter is \emph{context splitting}, as showcased by the typing rule for parallel composition.

\todo{Insert related work focusing on noted issues with mechanising linearity.}

\paragraph{Scope extrusion.}
The encoding of binding constructs has been extensively studied for type systems based on $\lambda$-calculi, but process calculi present unique challenges.
$\pi$-calculi typically include several different binding constructs: inputs bind a received name or value, recursive processes bind recursion variables, and restrictions bind names.
The first two act similarly to the binders known from $\lambda$-calculi, but restrictions are more challenging due to scope extrusion.

\todo{Insert related work focusing on noted issues when mechanising scope extrusion.}

\cite{Maksimovic2015} does not have name restriction, thus dodging the challenge of scope extrusion.

\paragraph{Coinduction.} \todo{explain more what the challenge does.}
Coinduction is fundamental to establish properties of processes that
may never terminate, which is a typical situation. We base our challenge around
bisimulation: a coinductively established property for equating the
observed behaviour of potentially infinite processes.

Common uses for coinduction are to define strong and weak versions of
bisimulation, barbed notions of bisimulation, prove trace equivalence,
etc.

In this challenge we study the notion of strong barbed bisimulation
over a fragment of the $\pi$-calculus.

\todo{Insert related work focusing on noted issues when mechanising coinduction.}

\subsection{Goals and how to contribute}
Similarly to the authors of the POPLMark challenges, we seek to
answer several questions:
%\alb{We oscillate between concurrency in general and process calculi, here and before}
\begin{enumerate}[label=\textbf{(Q\arabic*)},leftmargin=10mm]
\item\label{item:rq1} What is the current state of the art in mechanising process calculi?
\item\label{item:rq2} Which techniques and best practices can be recommended when starting formalisation projects involving process calculi?
\item\label{item:rq3} Which improvements are needed to make mechanisation tools more user-friendly with regards to the issues faced when mechanising process calculi?
\end{enumerate}

To provide a framework in which to answer these questions, our benchmark is designed to satisfy three main goals:
\begin{enumerate}[label=\textbf{(G\arabic*)},leftmargin=10mm]
\item\label{item:goal-comperison-accessibility} To enable the comparison of
  proof mechanisation approaches, making the challenges accessible to
  mechanisation experts who may be unfamiliar with concurrency theory;

\item\label{item:goal-tutorials} To encourage the development of guidelines and
  tutorials demonstrating and comparing existing proof mechanisation
  techniques, libraries, and proof assistant features; and

\item\label{item:goal-reusability} To prioritise the exploration of mechanisation
  techniques that are reusable for future research.
\end{enumerate}
We also aim at strengthening the culture of mechanisation, by rallying the community to collaborate on exploring and developing new tools and techniques.

We have begun collecting solutions to our challenges on our website:
%
\begin{center}
  \url{https://concurrentbenchmark.github.io/}
\end{center}
%
In the longer term, we expect to use the website for promoting best practices, tutorials and guidelines derived from solutions to our challenges.
We encourage anyone interested to try the challenges using their favourite tools and techniques, and to send us their solutions.


% - Design of the benchmark
%   - We first list some general design remarks, then for each challenge
%   - General remarks
%     - We do not aim to be comprehensive (list other topics)
%     - However, we believe the best practices developed could also be of use in those topics
%     - We base our challenges on basic textbook theory with interesting proof techniques
%     - The challenges are independent (maybe note ``failure'' of POPLMark that everyone only did the first part)
%     - The challenges are as minimal as possible
%   - Linearity
%     - Type preservation for session types
%     - The main issue is context splitting
%     - Session types are pervasive in the field and simple to understand
%     - Binding two names makes duality obvious
%     - Brief overview of approaches and issues with them
%   - Scope extrusion
%     - Process calculi have several binders, but only restriction is different from ``normal'' ones
%     - The main issue is scope extrusion
%     - The pros and cons of established techniques for handling binders are different for process calculi, and it is unclear how exactly
%     - Brief overview of approaches and issues with them
%   - Coinduction
%     - Strong barbed bisimulation and congruence
%     - The main issue is the encoding of coinductive up-to techniques
%     - Strong equivalences to simplify (we don't have to abstract over internal transitions)
%     - Why barbed equivalences?
%     - No delegation to simplify
%     - Brief overview of approaches and issues with them
%   - Evaluation criteria
%     - We care not only about solutions, but about experiences and comparisons
%     - Mechanisation overhead
%     - Adequacy of the formal statements
%     - Cost of entry for tools and techniques
%     - Slight changes are OK if they are justified and adequate
\section{Design of the Benchmark}\label{sec:design-discussion}
\todo{Add references to support our claims and decisions in this whole section. Here is where we should mention existing approaches.}

In this section, we outline the factors considered in designing the benchmark challenges.
We begin with some general remarks, then describe the individual design considerations for each challenge problem, and the evaluation criteria for solutions.

\subsubsection{General design remarks.}
Like the POPLMark and POPLMark Reloaded challenges, our challenge is not meant to be comprehensive:
applications such as multiparty session types~\cite{10.1145/2827695,10.1145/3290343}, choreographies~\cite{DBLP:journals/jar/CruzFilipeMP23}, conversation types~\cite{DBLP:journals/tcs/CairesV10}, psi-calculi~\cite{lmcs:696}, or encodings between different calculi~\cite{DBLP:journals/iandc/Gorla10,DBLP:conf/forte/CairesP16,DBLP:journals/iandc/DardhaGS17,DBLP:conf/ecoop/ScalasDHY17,DBLP:journals/iandc/KouzapasPY19,10.1145/3479394.3479407} are not directly covered.\alb{Do we need all those citations about encodings?}
Still, these (and other) applications need the basic techniques that our challenge problems emphasize: as per design goal \ref{item:goal-reusability}, our problems are drawn from the basic meta-theory of process calculi (without requiring the development of new theory), and focus on well-known theorems and results that involve interesting proof techniques that may be reused in further work.
To achieve design goal \ref{item:goal-comperison-accessibility},
we have formulated our challenge problems to explore the three aspects (linearity, scope extrusion, coinduction) independently, so that they may be solved individually and in any order;
each problem should be reasonably small and easily understood with basic knowledge of textbook concurrency theory, process calculi, and type theory.  The process calculus used in each challenge
focuses on the features that we want to emphasize, and omits all constructs
(such as choices) that would complicate the mechanisation without bringing additional tangible
benefits and insights. 
The minimality and uniformity of the calculi also allows us to target design
goal \ref{item:goal-tutorials}.

\subsubsection{Linearity.}
While a linear context is perhaps best seen as a multi-set, most proof assistants have better support for list processing.
The latter representation is intuitive, but may require establishing a large number of technical lemmata that are orthogonal to the mathematics of the problem under study, say proving type preservation for session types.
In this space, several designs are possible: one can label occurrences of resources to constrain their usage (\eg~\cite{CicconeP20}) or \alb{something --- ask Francisco} as in \cite{Castro2020}.
Some authors instead impose a multiset structure over lists (\eg~\cite{ChaudhuriLR19,Danielsson12}); still, the effort required to develop the infrastructure is significant.

A different approach is to bypass the problem of context splitting by adopting familiar ideas from algorithmic linear type checking: this is known as \emph{typing with leftovers}, as exemplified in~\cite{DBLP:conf/forte/ZalakainD21}.
Whatever the choice, list-based encodings can be refined to be intrinsically-typed, if the proof assistant does support dependent types (see~\cite{Thiemann2019,CicconeP20,RouvoetPKV20}).

For something completely different, one could adopt a \emph{sub-structural} meta-logical framework: here the framework itself handles resource distribution, and users need only map their linear operations to the ones offered by the framework.
In fact, the linear function space will handle all context operations implicitly, including splitting and substitution.
One such framework is \emph{Celf}~\cite{Schack-Nielsen:IJCAR08} (see the encoding of session types in~\cite{Bock2016}).
Unfortunately, \emph{Celf} does not yet fully support the verification of meta-theoretic properties.
A compromise is the so called \emph{two-level} approach, where one encodes a sub-structural specification logic in a mainstream proof assistant and then uses that logic to state and prove linear properties (for a recent example, see~\cite{Felty:MSCS21}).

\todo{Insert discussion/related work focusing on existing techniques and how our benchmark design makes it possible to compare them.}

For our challenge on linear reasoning we have chosen a type preservation theorem
for a system using session types.
% , whose use are common in concurrency theory.
This allows us to introduce linear reasoning with few definitions.
With our objective focused on linearity, we forego channel delegation
and opt for a reduction approach rather than employing a transition
system semantics.  Inspired by Vasconcelos~\cite{Vasconcelos2012}, we
define a syntax where restriction binds two names,n highlighting
their duality within the type system.  We have chosen a simple notion
of well-formedness, and do not  consider
deadlocks. While more sophisticated notions of well-formedness are
interesting, the proofs of these properties would distract from the
core linear aspects of the challenge.

\subsubsection{Scope extrusion.}
This is the challenge most closely related to the POPLMark challenge
since it concerns the properties of binders in restrictions and input.

The case study \cite{AmbalLS21} compares four approaches to encoding binders in Coq as a first step towards developing tools for working with higher-order process calculi.
They found that working directly with de Bruijn indices was easiest and shortest since the existing approaches developed for $\lambda$-calculus binders do not work well with scope extrusion.
Specifically, the locally nameless representation~\cite{Chargueraud2012} cannot avoid direct manipulation of de Bruijn indices when defining the semantics of scope extrusion; cofinite quantification provides no benefits when working under binders; nominal approaches~\cite{Pitts2003} require explicitly giving and validating sets of free names during scope extrusion; and higher-order abstract syntax (HOAS)~\cite{Pfenning1988} requires additional axioms to work with contexts.

\todo{Insert discussion/related work focusing on existing techniques and how our benchmark design makes it possible to compare them.}

Additionally, many proof assistants lack support for the proof principles required to easily work with scope extrusion, \ie, induction principles on functions to work with HOAS encodings.
Some proof assistants such as Abella~\cite{Baelde2014} support HOAS natively, but working with open terms as required to encode scope extrusion in these systems is generally very challenging~\cite{Momigliano2012}.

\subsubsection{Coinduction.}
Coinduction is widely supported in proof assistants.
Isabelle, Coq, and Abella seamlessly support coinductive definitions and reasoning.
Agda and Beluga support it through the convenient abstraction of co-patterns~\cite{Abel2013}.
Newer entrants to the field like the Lean proof assistant are working on adding a notion of coinduction to their system~\cite{Avigad2019,Keizer2023}.

As with most features, proof assistants support subtly different formalisms that enable different techniques and motivate this challenge.
Some systems provide more than one abstraction to use coinduction.
A good example of this are the parameterized coinduction~\cite{Hur2013} and interaction tree~\cite{Xia2019} libraries for Coq.

\todo{Insert discussion/related work focusing on existing techniques and how our benchmark design makes it possible to compare them.}

Our coinduction challenge concerns strong barbed bisimulation and
congruence.\alb{we motivate why strong vs weak, but not why barbed}
Though weak barbed congruence is a more common behavioural equivalence
w.r.t.\ the \(\pi\)-calculus, here we prefer strong equivalences to avoid the
need to abstract over the number of internal transitions, thus
simplifying the theory.  We exclude delegation from the coinduction
challenge since it is orthogonal to our primary aim of exploring
coinductive proof techniques.

\subsubsection{Evaluation criteria.}
The idea behind our benchmark is to obtain evidence towards answering questions \cref{item:rq1,item:rq2,item:rq3}. We are therefore interested in not only the solutions, but also in the experience of solving the challenges with the chosen approach.
Solutions to our challenges should be compared on three measures:
\begin{enumerate}
\item Mechanisation overhead: the amount of manually written infrastructure and setup needed to express the definitions in the mechanisation;
\item Adequacy of the formal statements in the mechanisation: whether the proven theorems are easily recognisable as the theorems from the challenge; and
\item Cost of entry for the tools and techniques employed: the difficulty of learning to use the techniques.
\end{enumerate}
Solutions to our challenges do not need to strictly follow the definitions and lemmata set out in the problem text, but solutions which deviate from the original challenges must present more elaborate argumentation for their adequacy.


% - Going beyond the challenge problems
%   - We do not aim to be comprehensive, but the techniques should also be useful for other things
%   - Our challenges are independent, but they can also be combined
%   - Our challenges are basic textbook theory, so they can form the basis for many extensions
%   - Our aim is to see a future where ``the basics'' are as trivial in mechanisations as they are on paper
\section{Going beyond the challenge problems}\label{sec:going-beyond}
Similarly to POPLMark and its Reloaded counterpart, our challenges do not encompass all issues in the field.
Our benchmark is extendable in two aspects: one can further amalgamate and broaden the existing challenges, or tackle aspects not covered by the benchmark at all.
Any of these extensions will still need to handle at least one of the key aspects of our challenges.
\todo{Frederik: Does splitting this section up into these two categories still make sense? We could save some space by not doing so, and it is not obvious to me what exactly should be on each side of the split.}

\paragraph{Extending and combining the current challenges.}
We have aimed to reduce the overlap of the aspects (linearity, scope extrusion, coinduction) that our challenges involve.
Most concurrency theory research needs several of the aspects and often also other constructs that we have chosen not to cover for simplicity.
We suggest three extensions that would be useful for many applications:
\emph{(1)} adding choice constructs to both type and process levels,
\emph{(2)} introducing recursion and recursive types for typed systems, and
\emph{(3)} incorporating channel delegation in calculi lacking it.

\paragraph{Addressing new calculi and new features.}
\todo{Mention the higher-order pi calculus?}
Extending in this direction means proposing new challenges covering different features of process calculi, or different proof mechanisation features.
Some interesting aspects of message-passing calculi to be explored in further challenges could be multiparty session types~\cite{10.1145/2827695} and choreographies~\cite{Carbone2013}, as their meta-theory includes aspects -- \eg well-formedness conditions on global types, partiality of end-point projection function, \etc -- that we do not address here.
Also, one could easily design a challenge that goes beyond our coinduction challenge, by exploring different notions of bisimilarity (barbed, weak, \etc) and trace equivalence.
%
Coinduction may also play a relevant role in supporting recursive processes and
session types. Indeed, it is often the case that session type systems (and
logics) with recursive session types (and propositions) are naturally expressed
in \emph{infinitary form} by interpreting their typing (and proof) rules
coinductively~\cite{BaeldeDoumaneSaurin16,DerakhshanPfenning22,HornePadovani23}.

On the mechanisation side, the present challenge proposes mechanising the proofs of theorems.
An interesting avenue to explore would be to take advantage of other proof assistant features like extracting certified implementations.
Additionally, while our current challenge is agnostic about proof automation, a more specific challenge could be designed with the objective of automating aspects of the proofs.
Finally, a challenge could propose the integration with other formal reasoning tools, such as model checkers.
These tools are in common use in the field; combining automated proofs with proof assistants offers the potential to ease the path towards larger proofs.

Ultimately, the current challenges can be extended in several worthwhile directions, and we look forward to a future when they indeed are.
We see the current challenge as setting the foundation for those future extensions.
It is our hope and aim that our challenges will move us closer to a future where the key basic proof techniques are as easy to mechanise as they are to write on paper.

\bibliographystyle{splncs04}
\bibliography{../references}

\clearpage
\appendix
\section{Challenges}\label{app:challenges}
\input{../challenges/challenges.tex}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
