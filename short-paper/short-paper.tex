\documentclass[runningheads]{llncs}
\synctex=1
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{graphicx}
\usepackage{mathpartir}
\usepackage{cite}
\usepackage{bm}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage{hyperref}
\usepackage{microtype}
\usepackage[inline]{enumitem}
\usepackage{color}
\renewcommand\UrlFont{\color{blue}\rmfamily}

\usepackage[status=draft]{fixme}
\fxsetup{theme=color}
% \setlength{\textwidth}{12.4cm}
\setlength{\textheight}{19.9cm}

\input{../macros.tex}

\begin{document}

\title{The Concurrent Calculi Formalisation Benchmark}

\author{
     Marco Carbone \inst{1}\orcidID{0000-0001-9479-2632}
\and David Castro-Perez \inst{2}\orcidID{0000-0002-6939-4189}
\and Francisco Ferreira \inst{3}\orcidID{0000-0001-8494-7696}
\and Lorenzo Gheri \inst{4}\orcidID{0000-0002-3191-7722}
\and Frederik Krogsdal Jacobsen \inst{5}\orcidID{0000-0003-3651-8314}
\and Alberto Momigliano \inst{6}\orcidID{0000-0003-0942-4777}
\and Luca Padovani \inst{7}\orcidID{0000-0001-9097-1297}
\and Alceste Scalas \inst{5}\orcidID{0000-0002-1153-6164}
\and Dawit Tirore \inst{1}\orcidID{0000-0002-1997-5161}
\and Martin Vassor \inst{8}\orcidID{0000-0002-2057-0495}
\and Nobuko Yoshida \inst{8}\orcidID{0000-0002-3925-8557}
\and Daniel Zackon \inst{9}\orcidID{0009-0008-6153-2955}
}

\institute{
     IT University of Copenhagen, Copenhagen, Denmark \email{maca@itu.dk}, \email{dati@itu.dk}
\and University of Kent, Canterbury, United Kingdom \email{d.castro-perez@kent.ac.uk}
\and Royal Holloway, University of London, Egham, United Kingdom \email{francisco.ferreiraruiz@rhul.ac.uk}
\and University of Liverpool, Liverpool, United Kingdom \email{lorenzo.gheri@liverpool.ac.uk}
\and Technical University of Denmark, Kgs. Lyngby, Denmark \email{fkjac@dtu.dk}, \email{alcsc@dtu.dk}
\and Università degli Studi di Milano, Milan, Italy \email{momigliano@di.unimi.it}
\and Università di Camerino, Camerino, Italy \email{luca.padovani@unicam.it}
\and University of Oxford, Oxford, United Kingdom \email{martin.vassor@cs.ox.ac.uk}, \email{nobuko.yoshida@cs.ox.ac.uk}
\and McGill University, Montreal, Canada \email{daniel.zackon@mcgill.ca}
}

\authorrunning{M. Carbone et al.}

\maketitle

\begin{abstract}
  POPLMark and POPLMark Reloaded sparked a flurry of work on machine-checked proofs, and fostered the adoption of proof mechanisation in programming language research.
  Both challenges were purposely limited in scope, and their benchmark problems do not address concurrency-related issues.
  %
  We propose a new collection of benchmark problems focused on the difficulties that typically arise when mechanising formal models of concurrent and distributed programming languages, such as process calculi.
  Our benchmark problems address three key topics: linearity, scope extrusion, and coinductive reasoning.
  The goal of this new challenge is to clarify, compare, and advance the state of the art, fostering the adoption of proof mechanisation in future research on message-passing concurrency. \todo{Broaden `message-passing concurrency' to `concurrency'?}

\keywords{Mechanisation \and Process calculi \and Benchmark \and Coinduction \and Scope extrusion \and Linearity}
\end{abstract}

\section{Introduction}
The POPLMark challenge~\cite{POPLMark}
played a pivotal role in advancing the field of proof assistants,
libraries, and best practices for programming language
mechanisation. By providing a shared framework for systematically
evaluating mechanisation techniques, it catalysed a significant
shift towards publications that include mechanised proofs within the programming language research community.
POPLMark Reloaded~\cite{POPLMarkReloaded} introduced a similar programme targeting proofs using logical relations.
These initiatives had a narrow focus, but their authors recognised the importance of addressing topics such as coinduction and linearity in the future.

In this spirit, we introduce a new collection of benchmark problems
specifically crafted to tackle common challenges encountered during
the mechanisation of formal models for concurrent and distributed
programming languages.
We particularly focus on process calculi.\todo{Why? - they are PL-like but also formal models in themselves}
Concurrent calculi are notably subtle: for instance, it took nine
years before the incorrect proof of type safety in the seminal paper
by Honda et al.~\cite{Honda1998} was rectified in Yoshida and
Vasconcelos’s subsequent work\cite{Yoshida2007}.
Similarly, several key results in papers on session types have turned out
to be false later on, illustrating the
value of machine-checked proofs~\cite{Gay2020,10.1145/3290343}.

While results about concurrent
formalisms have already been mechanised (as we will discuss further
below), our experience is that choosing appropriate mechanisation
techniques and tools remains a significant challenge and that the
trade-offs are not well understood.  This often leads researchers
toward a trial-and-error approach, resulting in sub-optimal solutions,
wasted mechanisation effort, and techniques and results that are hard
to reuse. For example, the authors in~\cite{Cruz-Filipe2021b} note that the high-level parts of
mechanised proofs closely resemble the informal ones, while the
main challenge lies in getting the infrastructure right.

Our benchmark problems (detailed in \cref{app:challenges} and on our website) consider
\emph{in isolation} three key aspects that frequently pose challenges
when mechanising concurrency theory: \emph{linearity}, \emph{scope
  extrusion}, and \emph{coinductive reasoning}.  Mechanisations must
often address several of these aspects at the same time; however, we
see the combination of techniques as a next
step, as discussed in \cref{sec:going-beyond}.
Our benchmark challenges are based on process calculi, as these provide a simple but
realistic showcase of common issues encountered during mechanisation
efforts.

We have begun collecting solutions to our challenges on our website:
%
\begin{center}
  \url{https://concurrentbenchmark.github.io/}
\end{center}
%
In the future, we expect to use the website to promote best practices and tutorials derived from solutions to our challenges.
We encourage readers to try the challenges using their favourite techniques, and to send us their solutions.

\section{The Benchmark and its Design}\label{sec:design-discussion}
In this section, we outline the factors considered in designing the benchmark challenges.
We begin with some general remarks, then describe the individual design considerations for each challenge problem, and the evaluation criteria for solutions.

Similarly to the authors of the POPLMark challenges, we seek to answer several questions:
\begin{enumerate}[label=\textbf{(Q\arabic*)},leftmargin=10mm]
\item\label{item:rq1} What is the current state of the art in the mechanisation of  the meta-theory of process calculi?
\item\label{item:rq2} Which techniques and best practices can be recommended when starting new mechanisation projects involving process calculi?
\item\label{item:rq3} Which improvements are needed to make mechanisation tools more user-friendly with regards to the issues faced when mechanising process calculi?
\end{enumerate}

To provide a framework in which to answer these questions, our benchmark is designed to satisfy three main design goals:
\begin{enumerate}[label=\textbf{(G\arabic*)},leftmargin=10mm]
\item\label{item:goal-comperison-accessibility} To enable the comparison of
  proof mechanisation approaches by making the challenges accessible to
  mechanisation experts who may be unfamiliar with concurrency theory;

\item\label{item:goal-tutorials} To encourage the development of guidelines and
  tutorials demonstrating and comparing existing proof mechanisation
  techniques, libraries, and proof assistant features; and

\item\label{item:goal-reusability} To prioritise the exploration of mechanisation
  techniques that are reusable for future research.
\end{enumerate}
We also aim at strengthening the culture of mechanisation, by rallying the community to collaborate on exploring and developing new tools and techniques.

To achieve design goal \ref{item:goal-comperison-accessibility}, we have
formulated our challenge problems to explore the three aspects
(linearity, scope extrusion, coinduction) independently, so that they
may be solved individually and in any order; each problem is
reasonably small and easily understandable with basic knowledge of
textbook concurrency theory, process calculi, and type theory.  The
process calculus used in each challenge focuses on the features that
we want to emphasise, and omits all constructs (such as choices) that
would complicate the mechanisation without bringing additional
tangible insights.  The minimality and uniformity of the
calculi also allows us to target design goal
\ref{item:goal-tutorials}.
Aligned with design goal~\ref{item:goal-reusability}, our problems are rooted in the fundamental meta-theory of process calculi, without necessitating the creation of novel theory.
Our challenges centre around well-established theorems and results, showcasing interesting proof techniques that can be leveraged in many applications (as we will further discuss in \cref{sec:going-beyond}).

\subsection{Linearity}
Linear typing systems allow  tracking the use of resources in a program. In
the case of typed process calculi (in particular, session types), linearity is
widely used for checking if and how a channel is used to send or receive values.
This leads to substructural typing~\cite[Chapter 1]{Pierce2004-oq} with
resulting mechanisation difficulties --- \eg deciding how to \emph{split the
typing context} in a parallel composition.

The goal of our challenge on linear reasoning is proving a type safety theorem
for a process calculus with session types, by combining as usual subject
reduction with absence of errors.  We have chosen  only to model linear (as
opposed to shared) channels. Inspired by Vasconcelos~\cite{Vasconcelos2012}, we
define a syntax where a restriction $(\nu ab)$ binds two dual names $a$
and $b$ as opposite endpoints of the same channel; their duality is
reflected in the type system. We model a simple notion of error: a well-typed
processes must never use dual channel endpoints in a non-dual way (\eg by
performing concurrent send/receive operations on the same endpoint, or two
concurrent send operations on both endpoints).
The operational semantics is formulated as a standard reduction relation. Thus,
proving subject reduction requires proving type preservation for structural
congruence.

We designed this challenge to focus on linear reasoning while minimising
definitions and other concerns.  We therefore forgo channel delegation:
send/receive operations only support values that do not include channels, so
the topology of the communication network described by a process cannot change.
We do not allow recursion or replication, so infinite behaviours cannot be
expressed. We also forgo more sophisticated notions of error-freedom (\eg
deadlock freedom) because proving them would distract from the core linear
aspects of the challenge.

In mechanised meta-theory, addressing linearity means choosing an appropriate
representation of the linear typing context.  While a linear context is perhaps
best seen as a multiset, most proof assistants have better support for list
processing.  The latter representation is intuitive, but may require
establishing a large number of technical lemmata that are orthogonal to the
problem under study (in our case, proving type safety for
session types).  In this space, several designs are possible: one can label
occurrences of resources to constrain their usage (\eg~\cite{CicconeP20}); some
authors instead impose a multiset structure over lists
(\eg~\cite{Danielsson12,ChaudhuriLR19}). Alternatively, contexts can be
implemented as finite maps (as in \cite{Castro2020}), whose operations are
sensitive to a linear discipline. In all these cases, the effort required to
develop the infrastructure is significant.
%
One alternative strategy is to bypass the problem of context splitting
by adopting familiar ideas from algorithmic linear type checking. This
approach, referred to as ``typing with leftovers,'' is exemplified
in~\cite{DBLP:conf/forte/ZalakainD21}.  Whatever the choice,
list-based encodings can be refined to be intrinsically-typed, if the
proof assistant supports dependent types
(see~\cite{Thiemann2019,CicconeP20,RouvoetPKV20}).
%
A radically different approach is to adopt a \emph{substructural}
meta-logical framework, which handles resource
distribution implicitly, including splitting and
substitution: users need only map their linear operations to the
ones offered by the framework.  The only such framework is
\emph{Celf}~\cite{Schack-Nielsen:IJCAR08} (see the encoding of session
types in~\cite{Bock2016}); unfortunately, \emph{Celf} does not yet
fully support the verification of meta-theoretic properties.  A
compromise is the so called \emph{two-level} approach, \ie encoding a
substructural specification logic in a mainstream proof assistant and
then using that logic to state and prove linear properties (for a
recent example, see~\cite{Felty:MSCS21}).

\subsection{Scope extrusion}
This challenge revolves around the mechanisation of scope
extrusion, by which a process can send restricted names to another
process, as long as the restriction can safely be extruded to include
the receiving process.  The setting for this challenge is a
``classic'' untyped \( \pi \)-calculus, where (unlike the calculi in
the other challenges) names can be sent and received, and bound by
input constructs.  We define two different semantics for our system:
\begin{enumerate}
\item A reduction system: this avoids explicit reasoning about scope
  extrusion by using instead structural congruence, allowing
  implementors to explore alternative ways to encode the latter (\eg
  via process contexts or via compatible refinement);
\item An (early) labelled transition system.
\end{enumerate}
The objective of this
challenge is to prove that the two semantics are equivalent up to
structural congruence.

This is the challenge most closely related to  POPLMark, 
since it concerns the properties of binders, whose encoding has been
extensively studied with respect to the $\lambda$-calculi. Process calculi
present additional challenges,  typically including several
different binding constructs: inputs bind a received name or value,
recursive processes bind recursion variables, and restrictions bind
names.  The first two act similarly to the binders known from
$\lambda$-calculi, but restrictions may be more challenging due to
scope extrusion.

Given those peculiarities, the syntax and semantics of $\pi$-calculi have been
mechanised from an early age (see~\cite{Melham1994}) with many proof
assistants and in so many encoding styles that it would take too long to
review.  They range from concrete encodings based on named syntax
\cite{Melham1994} to basic de Bruijn \todo{cite} and locally nameless
representation %~\cite{Chargueraud2012}
(\eg~\cite{Castro2020}).
Nominal approaches are also common (see~\cite{Bengtson2009}), but they
may be problematic in proof assistants based on dependent types.

\todo{Sum up some of those issues}
% \cite{Maksimovic2015} does not have
% name restriction, thus dodging the challenge of scope extrusion.
\begin{quotation}
\cite{Castro-Perez2021,Castro2020} note that popular presentations of
session type systems are impossible to directly encode using
intrinsically \(\alpha\)-convertible terms.  \cite{Castro2020}
suggests using several binder constructs to solve this, but notes that
this requires proving many variants of the same theorems.
The case study \cite{AmbalLS21} compares four approaches to encoding
binders in Coq as a first step towards developing tools for working
with higher-order process calculi.  They found that working directly
with de Bruijn indices was easiest and shortest since the existing
approaches developed for $\lambda$-calculus binders do not work well
with scope extrusion.  Specifically, the locally nameless
representation~\cite{Chargueraud2012} cannot avoid direct manipulation
of de Bruijn indices when defining the semantics of scope extrusion;
cofinite quantification provides no benefits when working under
binders; nominal approaches require explicitly giving
and validating sets of free names during scope extrusion;
\end{quotation}


Higher-order abstract syntax (HOAS) has seen extensive and successful
use in formal reasoning in this area~\cite{Despeyroux2000,Honsell2001,Tiu2010,ChaudhuriCM15}. Its
weak form aligns well with mainstream inductive proof assistants,
significantly simplifying the encoding of typing systems and operational
semantics. However, when addressing more intricate concepts like
bisimulation, HOAS necessitates extensions. These extensions may take
the form of additional axioms~\cite{Honsell2001} or require specialised proof assistants
like Abella, which introduces a dedicated quantifier for handling
properties related to names~\cite{GacekMN11}.

\subsection{Coinduction}

Process calculi typically include constructs that allow processes to
have infinite behaviours.  Coinduction serves as a fundamental method
for the definition and analysis of infinite objects, enabling the
examination of their behaviours.

The goal of our challenge on coinductive reasoning is proving that
\emph{strong barbed bisimilarity} can be turned into a congruence by making
it sensitive to substitution and parallel composition. The crux of our
challenge is the effective use of coinductive up-to techniques.  The
intention is that it should be easy to use the bisimulation relation
and its properties, but this may be difficult with some mechanisation
approaches.

The setting for our challenge is an untyped \(\pi\)-calculus augmented with
replication of processes in order to enable infinite behaviours.  We do not
include delegation since it is orthogonal to our
primary aim of exploring coinductive proof techniques.  We base our
definition of bisimilarity on a labelled transition system semantics
and an observability predicate describing the communication steps
available to a process.  The introduction of strong barbed
bisimulation is one of the first steps when studying the observable
behaviour of process calculi, both in classical textbooks (e.g.,
\cite{picalcbook}) and in existing mechanisations.  Though weak barbed
congruence is a more common behavioural equivalence, we prefer strong
equivalences to simplify the theory by avoiding the need to abstract
over the number of internal transitions in a trace.

While many proof assistants support coinductive techniques, they do so
through subtly different formalisms, enabling various approaches.
Additionally, some systems offer multiple abstractions for utilising coinduction.
For instance, Agda offers musical notation, co-patterns and sized types~\cite{Abel2013};
Coq offers guarded recursion and refined fixed point approaches as supported by the parameterised coinduction~\cite{Hur2013}
and interaction tree~\cite{Xia2019} libraries.

When reasoning over bisimilarity many authors rely on the native
 coinduction offered by the chosen proof assistants
\cite{Bengtson2016,Kahsai2008,Thiemann2019,Gay2020}, while others prefer a
more ``set-theoretic'' approach
\cite{Hirschkoff1997,Bengtson2009,Maksimovic2015,Pohjola2022}. Some
use both and establish an internal adequacy~\cite{Honsell2001}. Few
extend the proof assistant foundations to allow \eg reasoning about
bisimilarity up-to~\cite{ChaudhuriCM15}.
% While many proof assistants support
% coinductive techniques,   but they support subtly different formalisms that enable different techniques, and some systems provide more than one abstraction to use coinduction.
% We thus see a variety of different formalisation choices for
% bisimulations, sometimes ad-hoc for the specific result.

% \todo{Reorganize the rest of this section to be more coherent}
% Isabelle, Coq, and Abella seamlessly support coinductive definitions and reasoning.
% Agda and Beluga support it through the convenient abstraction of co-patterns~\cite{Abel2013}.
% Newer entrants to the field like the Lean proof assistant
% are working on adding a notion of coinduction to their system~\cite{Avigad2019}.\alb{I kinda object to ``seamlessly''. In Coq it's a mess, in Abella very very limited, sized types in Agda are shaky. I guess Isabelle is better}
% =======
% Process calculi often include constructs that allow processes to have infinite behaviours.
% Coinduction is a fundamental technique for defining and reasoning about infinite objects, and it can thus be used to reason about these behaviours.
% While many proof assistants support coinductive techniques, using them is notoriously difficult, and representations and proof techniques vary widely.
% The crux of our challenge is the effective use of coinductive up-to techniques.
% The intention is that it should be easy to use the bisimulation relation and its properties, but this may be difficult with some mechanisation approaches.

% The goal of our challenge on coinductive reasoning is proving that strong barbed bisimilarity can be turned into a congruence by making it sensitive to substitution and parallel composition.
% The setting for our challenge is an untyped \(\pi\)-calculus with replication of processes enabling infinite behaviours.
% We do not include delegation in the calculus since it is orthogonal to our primary aim of exploring coinductive proof techniques.
% We base our definition of bisimilarity on a labelled transition system semantics and an observability predicate describing the communication steps available to a process.
% The introduction of strong barbed bisimulation is one of the first steps when studying the observable behaviour of process calculi, both in classical textbooks (\eg, \cite{picalcbook}) and in existing mechanisations.
% Though weak barbed congruence is a more common behavioural equivalence, we prefer strong equivalences to simplify the theory by avoiding the need to abstract over the number of internal transitions in a trace.

% Coinduction is widely supported in proof assistants, but they support subtly different formalisms that enable different techniques, and some systems provide more than one abstraction to use coinduction.
% We thus see a variety of different formalisation choices for bisimulations, sometimes ad-hoc for the specific result.

% \todo{Reorganize the rest of this section to be more coherent}
% Isabelle, Coq, and Abella seamlessly support coinductive definitions and reasoning.
% Agda and Beluga support it through the convenient abstraction of co-patterns~\cite{Abel2013}.
% Newer entrants to the field like the Lean proof assistant
% are working on adding a notion of coinduction to their system~\cite{Avigad2019}.\alb{I kinda object to ``seamlessly''. In Coq it's a mess, in Abella very very limited, sized types in Agda are shaky. I guess Isabelle is better}

\subsection{Evaluation criteria.}
The idea behind our benchmark is to obtain evidence towards answering
questions \cref{item:rq1,item:rq2,item:rq3}. We are therefore
interested not only in the solutions, but also in the experience of
solving the challenges with the chosen approach.  Solutions to our
challenges should be compared on three axes:
\begin{enumerate}
\item Mechanisation overhead: the amount of manually written infrastructure and setup needed to express the definitions in the mechanisation;
\item Adequacy of the formal statements in the mechanisation: whether the proven theorems are easily recognisable as the theorems from the challenge; and
\item Cost of entry for the tools and techniques employed: the difficulty of learning to use the techniques.
\end{enumerate}
Solutions to our challenges do not need to strictly follow the definitions and lemmata set out in the problem text, but solutions which deviate from the original challenges must present more elaborate argumentation for their adequacy.


% - Going beyond the challenge problems
%   - We do not aim to be comprehensive, but the techniques should also be useful for other things
%   - Our challenges are independent, but they can also be combined
%   - Our challenges are basic textbook theory, so they can form the basis for many extensions
%   - Our aim is to see a future where ``the basics'' are as trivial in mechanisations as they are on paper

% We previously promise to discuss combinations of techniques and applications to more elaborate schemes
\section{Going Beyond the Challenge Problems}\label{sec:going-beyond}
\todo{Clean up this section to be more coherent.}
Our benchmark challenges do not cover all issues in the field, but focus on the fundamental textbook aspects of linearity, scope extrusion, and coinduction.
Many mechanisations need to combine techniques to handle several of these aspects, and some may also need to handle aspects that are not covered by our benchmark challenges at all.

% \cite{Brady2017} notes that using algebraic effects is unwieldy when there are many communication channels and suggests an experimental approach using dependent uniqueness types.
% \cite{Zalakain2019} notes that systems lacking linear types must simulate linearity, and that using a linearity predicate complicates congruences.
% They had to limit themselves to an asymmetric structural precongruence to be able to prove subject reduction.
Some authors have already described the difficulties that combining techniques may induce in a mechanisation, \eg~\cite{DBLP:conf/forte/ZalakainD21}.

Features that are in wide use, but not covered by our benchmark, include choice constructs and recursion.
Some interesting aspects of message-passing calculi include multiparty session types~\cite{10.1145/2827695} and choreographies~\cite{Carbone2013}, as their meta-theory includes aspects---\eg well-formedness conditions on global types, partiality of end-point projection function, \etc---that we do not address.
Other areas of interest include higher-order calculi~\cite{Hirsch2022}, conversation types~\cite{DBLP:journals/tcs/CairesV10}, psi-calculi~\cite{lmcs:696}, or encodings between different calculi~\cite{DBLP:journals/iandc/Gorla10,DBLP:journals/iandc/DardhaGS17}.

For coinduction, one could explore different notions of process equivalence.

Coinduction may also play a relevant role in supporting recursive processes and session types.
Indeed, it is often the case that session type systems with recursive session types are naturally expressed in \emph{infinitary form} by interpreting their typing rules
coinductively~\cite{DerakhshanPfenning22,HornePadovani23}.

Finally, another interesting avenue to explore would be to take
advantage of certain proof assistant features: for example, extracting
certified implementations (as in \cite{Castro-Perez2021}) or exploiting
proof automation, such as the one offered by the \emph{Hammer}
protocol~\cite{BohmeN10,CzajkaK18}.

Ultimately, our challenges can be extended in several worthwhile directions, and we look forward to a future where they indeed are.
It is our hope and aim that our challenges will move us closer to a future where the key basic proof techniques for concurrent calculi are as easy to mechanise as they are to write on paper.

\bibliographystyle{splncs04}
\bibliography{../references}

\clearpage
\appendix
\section{Challenges}\label{app:challenges}
\input{../challenges/challenges.tex}

\end{document}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% End:
