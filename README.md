# The Concurrent Calculi Formalisation Benchmark

## Motivation
POPLMark and POPLMark Reloaded sparked a flurry of work on machine-checked proofs, and fostered the adoption of proof mechanisation in programming language research. Both challenges were purposely limited in scope, and they do not address concurrency-related issues. We propose a new collection of benchmark challenges focused on the difficulties that typically arise when mechanising formal models of concurrent and distributed programming languages, such as process calculi. Our benchmark challenges address three key topics: linearity, scope extrusion, and coinductive reasoning. The goal of this new benchmark is to clarify, compare, and advance the state of the art, fostering the adoption of proof mechanisation in future research on concurrency.

## COORDINATION paper
A paper describing the background and motivation for the benchmark in more detail was published in the proceedings of COORDINATION 2024. It can be found [here](https://doi.org/10.1007/978-3-031-62697-5_9).

## Detailed challenge descriptions
The detailed descriptions of the benchmark challenges can be found [here](https://concurrentbenchmark.github.io/concurrentbenchmark/Concurrent-Calculi-Formalisation-Benchmark.pdf) or compiled from the sources in the `challenges` directory.
